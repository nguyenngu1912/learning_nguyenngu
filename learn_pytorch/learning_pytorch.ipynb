{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946509ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version used by PyTorch: 12.6\n",
      "GPU name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# test version\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version used by PyTorch: {torch.version.cuda}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1185a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# ---------WORKING WITH DATA--------------\n",
    "# PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset. \n",
    "# Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset. \n",
    "# The torchvision.datasets module contains Dataset objects for many real-world vison data like CIFAR, COCO.\n",
    "# Every TorchVision dataset includes 2 arguments: transform and target_transform to modify the samples and labels respectively.\n",
    "\n",
    "\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51ff9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N,C,H,W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# We pass the Dataset as an argument to DataLoader. this wraps an iterable over our Dataset and supports automatic batching, sampling, \n",
    "# shufflling and multiprocess data loading. Here we decide a batch size of 64\n",
    "\n",
    "batch_size = 64    #each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "#create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N,C,H,W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    break\n",
    "\n",
    "# Output\n",
    "\n",
    "# Shape of X [N,C,H,W]: torch.Size([64, 1, 28, 28])\n",
    "# 64: Batch size - there are 64 images in this batch\n",
    "# 1: Number of channels - these are grayscale images (1 channel)\n",
    "# 28: Height - each image is 28 pixels tall\n",
    "# 28: Width - each image is 28 pixels wide\n",
    "\n",
    "# Shape of y: torch.Size([64]) \n",
    "# 64 labels for each of 64 images in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8b1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#-------------------CREATING MODELS----------------------\n",
    "# To define a neral network in Pytorch, we create a class that inherits from nn.Module.\n",
    "# We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function.\n",
    "\n",
    "# Use torch.accelerator to accelerator operations in the neural network.\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):                        # NeuralNetwork class inherits from nn.Module ,nn.Module is PyTorch's base class for all network components.\n",
    "    def __init__(self):                                # [64, 1, 28, 28] â†’ [64, 784] (64 batches, 784 features)\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()                    # Create a flattening layer that converts 2D to 1D vectors, needed because linear layers expect 1D input. \n",
    "        self.linear_relu_stack = nn.Sequential(        # nn.Sequential()): Container that chains multiple layers together, execute in order from input to output\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2753fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------OPTIMIZE THE MODEL PARAMETERS-------------------------\n",
    "# To train a model, we need a loss function and an optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)\n",
    "\n",
    "# In a single training loop, the model makes predictions on the training dataset (fed to it in batches), \n",
    "# and backpropagates the prediction error to adjust the model's parameters.\n",
    "\n",
    "def train(dataloader, model, loss_func, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y= X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_func(pred,y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch  + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d4e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model's performence to ensure it is learning\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b506dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.161928 [   64/60000]\n",
      "loss: 1.158481 [ 6464/60000]\n",
      "loss: 0.978176 [12864/60000]\n",
      "loss: 1.121189 [19264/60000]\n",
      "loss: 0.984356 [25664/60000]\n",
      "loss: 1.021807 [32064/60000]\n",
      "loss: 1.050056 [38464/60000]\n",
      "loss: 0.985201 [44864/60000]\n",
      "loss: 1.042055 [51264/60000]\n",
      "loss: 0.960111 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.982296 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.042994 [   64/60000]\n",
      "loss: 1.058550 [ 6464/60000]\n",
      "loss: 0.862283 [12864/60000]\n",
      "loss: 1.028735 [19264/60000]\n",
      "loss: 0.894240 [25664/60000]\n",
      "loss: 0.926581 [32064/60000]\n",
      "loss: 0.973912 [38464/60000]\n",
      "loss: 0.909596 [44864/60000]\n",
      "loss: 0.961536 [51264/60000]\n",
      "loss: 0.894464 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.909716 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.956917 [   64/60000]\n",
      "loss: 0.990426 [ 6464/60000]\n",
      "loss: 0.780415 [12864/60000]\n",
      "loss: 0.963603 [19264/60000]\n",
      "loss: 0.834470 [25664/60000]\n",
      "loss: 0.857575 [32064/60000]\n",
      "loss: 0.921135 [38464/60000]\n",
      "loss: 0.859321 [44864/60000]\n",
      "loss: 0.903485 [51264/60000]\n",
      "loss: 0.847574 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.857815 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.891130 [   64/60000]\n",
      "loss: 0.939874 [ 6464/60000]\n",
      "loss: 0.720156 [12864/60000]\n",
      "loss: 0.915195 [19264/60000]\n",
      "loss: 0.792006 [25664/60000]\n",
      "loss: 0.806073 [32064/60000]\n",
      "loss: 0.881272 [38464/60000]\n",
      "loss: 0.824366 [44864/60000]\n",
      "loss: 0.860196 [51264/60000]\n",
      "loss: 0.811934 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.818584 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.838539 [   64/60000]\n",
      "loss: 0.899243 [ 6464/60000]\n",
      "loss: 0.673710 [12864/60000]\n",
      "loss: 0.877779 [19264/60000]\n",
      "loss: 0.759953 [25664/60000]\n",
      "loss: 0.766672 [32064/60000]\n",
      "loss: 0.849101 [38464/60000]\n",
      "loss: 0.798554 [44864/60000]\n",
      "loss: 0.826873 [51264/60000]\n",
      "loss: 0.783299 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.787385 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.795003 [   64/60000]\n",
      "loss: 0.864626 [ 6464/60000]\n",
      "loss: 0.636405 [12864/60000]\n",
      "loss: 0.847769 [19264/60000]\n",
      "loss: 0.734472 [25664/60000]\n",
      "loss: 0.735353 [32064/60000]\n",
      "loss: 0.821354 [38464/60000]\n",
      "loss: 0.778279 [44864/60000]\n",
      "loss: 0.800106 [51264/60000]\n",
      "loss: 0.759161 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.761409 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.757669 [   64/60000]\n",
      "loss: 0.834143 [ 6464/60000]\n",
      "loss: 0.605360 [12864/60000]\n",
      "loss: 0.823030 [19264/60000]\n",
      "loss: 0.713148 [25664/60000]\n",
      "loss: 0.709879 [32064/60000]\n",
      "loss: 0.796513 [38464/60000]\n",
      "loss: 0.761353 [44864/60000]\n",
      "loss: 0.777616 [51264/60000]\n",
      "loss: 0.738000 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.738908 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.725016 [   64/60000]\n",
      "loss: 0.806744 [ 6464/60000]\n",
      "loss: 0.578868 [12864/60000]\n",
      "loss: 0.802113 [19264/60000]\n",
      "loss: 0.694757 [25664/60000]\n",
      "loss: 0.688750 [32064/60000]\n",
      "loss: 0.773561 [38464/60000]\n",
      "loss: 0.746617 [44864/60000]\n",
      "loss: 0.758327 [51264/60000]\n",
      "loss: 0.718991 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.718871 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.695926 [   64/60000]\n",
      "loss: 0.781737 [ 6464/60000]\n",
      "loss: 0.555810 [12864/60000]\n",
      "loss: 0.783955 [19264/60000]\n",
      "loss: 0.678788 [25664/60000]\n",
      "loss: 0.671009 [32064/60000]\n",
      "loss: 0.751921 [38464/60000]\n",
      "loss: 0.733361 [44864/60000]\n",
      "loss: 0.741449 [51264/60000]\n",
      "loss: 0.701573 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.700736 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.669849 [   64/60000]\n",
      "loss: 0.758873 [ 6464/60000]\n",
      "loss: 0.535520 [12864/60000]\n",
      "loss: 0.767944 [19264/60000]\n",
      "loss: 0.664755 [25664/60000]\n",
      "loss: 0.655773 [32064/60000]\n",
      "loss: 0.731613 [38464/60000]\n",
      "loss: 0.721488 [44864/60000]\n",
      "loss: 0.726457 [51264/60000]\n",
      "loss: 0.685436 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.684162 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.646317 [   64/60000]\n",
      "loss: 0.737905 [ 6464/60000]\n",
      "loss: 0.517533 [12864/60000]\n",
      "loss: 0.753550 [19264/60000]\n",
      "loss: 0.652285 [25664/60000]\n",
      "loss: 0.642605 [32064/60000]\n",
      "loss: 0.712626 [38464/60000]\n",
      "loss: 0.710844 [44864/60000]\n",
      "loss: 0.713157 [51264/60000]\n",
      "loss: 0.670328 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.668932 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.624979 [   64/60000]\n",
      "loss: 0.718557 [ 6464/60000]\n",
      "loss: 0.501398 [12864/60000]\n",
      "loss: 0.740452 [19264/60000]\n",
      "loss: 0.641268 [25664/60000]\n",
      "loss: 0.631211 [32064/60000]\n",
      "loss: 0.695022 [38464/60000]\n",
      "loss: 0.701456 [44864/60000]\n",
      "loss: 0.701635 [51264/60000]\n",
      "loss: 0.656190 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.654895 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.605530 [   64/60000]\n",
      "loss: 0.700683 [ 6464/60000]\n",
      "loss: 0.486902 [12864/60000]\n",
      "loss: 0.728516 [19264/60000]\n",
      "loss: 0.631449 [25664/60000]\n",
      "loss: 0.621269 [32064/60000]\n",
      "loss: 0.678414 [38464/60000]\n",
      "loss: 0.693268 [44864/60000]\n",
      "loss: 0.691659 [51264/60000]\n",
      "loss: 0.642821 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.641982 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.587913 [   64/60000]\n",
      "loss: 0.684180 [ 6464/60000]\n",
      "loss: 0.473758 [12864/60000]\n",
      "loss: 0.717492 [19264/60000]\n",
      "loss: 0.622765 [25664/60000]\n",
      "loss: 0.612412 [32064/60000]\n",
      "loss: 0.662973 [38464/60000]\n",
      "loss: 0.686362 [44864/60000]\n",
      "loss: 0.683062 [51264/60000]\n",
      "loss: 0.630169 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.630070 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.571821 [   64/60000]\n",
      "loss: 0.668980 [ 6464/60000]\n",
      "loss: 0.461711 [12864/60000]\n",
      "loss: 0.707118 [19264/60000]\n",
      "loss: 0.614913 [25664/60000]\n",
      "loss: 0.604605 [32064/60000]\n",
      "loss: 0.648680 [38464/60000]\n",
      "loss: 0.680572 [44864/60000]\n",
      "loss: 0.675754 [51264/60000]\n",
      "loss: 0.618248 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.619088 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.557154 [   64/60000]\n",
      "loss: 0.654916 [ 6464/60000]\n",
      "loss: 0.450678 [12864/60000]\n",
      "loss: 0.697543 [19264/60000]\n",
      "loss: 0.607737 [25664/60000]\n",
      "loss: 0.597670 [32064/60000]\n",
      "loss: 0.635417 [38464/60000]\n",
      "loss: 0.675844 [44864/60000]\n",
      "loss: 0.669639 [51264/60000]\n",
      "loss: 0.606912 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.609003 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.543740 [   64/60000]\n",
      "loss: 0.641883 [ 6464/60000]\n",
      "loss: 0.440591 [12864/60000]\n",
      "loss: 0.688640 [19264/60000]\n",
      "loss: 0.601064 [25664/60000]\n",
      "loss: 0.591452 [32064/60000]\n",
      "loss: 0.623203 [38464/60000]\n",
      "loss: 0.672043 [44864/60000]\n",
      "loss: 0.664564 [51264/60000]\n",
      "loss: 0.596101 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.599711 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.531380 [   64/60000]\n",
      "loss: 0.629899 [ 6464/60000]\n",
      "loss: 0.431310 [12864/60000]\n",
      "loss: 0.680333 [19264/60000]\n",
      "loss: 0.594737 [25664/60000]\n",
      "loss: 0.585719 [32064/60000]\n",
      "loss: 0.611975 [38464/60000]\n",
      "loss: 0.669119 [44864/60000]\n",
      "loss: 0.660329 [51264/60000]\n",
      "loss: 0.585770 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.591139 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.519917 [   64/60000]\n",
      "loss: 0.618792 [ 6464/60000]\n",
      "loss: 0.422734 [12864/60000]\n",
      "loss: 0.672560 [19264/60000]\n",
      "loss: 0.588786 [25664/60000]\n",
      "loss: 0.580386 [32064/60000]\n",
      "loss: 0.601699 [38464/60000]\n",
      "loss: 0.666954 [44864/60000]\n",
      "loss: 0.656909 [51264/60000]\n",
      "loss: 0.575949 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.583223 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.509207 [   64/60000]\n",
      "loss: 0.608495 [ 6464/60000]\n",
      "loss: 0.414760 [12864/60000]\n",
      "loss: 0.665188 [19264/60000]\n",
      "loss: 0.582996 [25664/60000]\n",
      "loss: 0.575423 [32064/60000]\n",
      "loss: 0.592251 [38464/60000]\n",
      "loss: 0.665459 [44864/60000]\n",
      "loss: 0.654061 [51264/60000]\n",
      "loss: 0.566516 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.575893 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.499203 [   64/60000]\n",
      "loss: 0.598920 [ 6464/60000]\n",
      "loss: 0.407371 [12864/60000]\n",
      "loss: 0.658267 [19264/60000]\n",
      "loss: 0.577311 [25664/60000]\n",
      "loss: 0.570797 [32064/60000]\n",
      "loss: 0.583488 [38464/60000]\n",
      "loss: 0.664577 [44864/60000]\n",
      "loss: 0.651701 [51264/60000]\n",
      "loss: 0.557406 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.569100 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.489807 [   64/60000]\n",
      "loss: 0.590024 [ 6464/60000]\n",
      "loss: 0.400507 [12864/60000]\n",
      "loss: 0.651682 [19264/60000]\n",
      "loss: 0.571708 [25664/60000]\n",
      "loss: 0.566354 [32064/60000]\n",
      "loss: 0.575431 [38464/60000]\n",
      "loss: 0.664175 [44864/60000]\n",
      "loss: 0.649805 [51264/60000]\n",
      "loss: 0.548636 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.562792 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.481021 [   64/60000]\n",
      "loss: 0.581784 [ 6464/60000]\n",
      "loss: 0.394083 [12864/60000]\n",
      "loss: 0.645404 [19264/60000]\n",
      "loss: 0.566129 [25664/60000]\n",
      "loss: 0.562012 [32064/60000]\n",
      "loss: 0.568024 [38464/60000]\n",
      "loss: 0.664248 [44864/60000]\n",
      "loss: 0.648216 [51264/60000]\n",
      "loss: 0.540152 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.556925 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.472711 [   64/60000]\n",
      "loss: 0.574101 [ 6464/60000]\n",
      "loss: 0.388082 [12864/60000]\n",
      "loss: 0.639375 [19264/60000]\n",
      "loss: 0.560606 [25664/60000]\n",
      "loss: 0.557773 [32064/60000]\n",
      "loss: 0.561146 [38464/60000]\n",
      "loss: 0.664590 [44864/60000]\n",
      "loss: 0.646790 [51264/60000]\n",
      "loss: 0.531991 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.551460 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.464855 [   64/60000]\n",
      "loss: 0.566983 [ 6464/60000]\n",
      "loss: 0.382400 [12864/60000]\n",
      "loss: 0.633522 [19264/60000]\n",
      "loss: 0.555106 [25664/60000]\n",
      "loss: 0.553559 [32064/60000]\n",
      "loss: 0.554787 [38464/60000]\n",
      "loss: 0.665188 [44864/60000]\n",
      "loss: 0.645490 [51264/60000]\n",
      "loss: 0.524091 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.546366 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.457388 [   64/60000]\n",
      "loss: 0.560362 [ 6464/60000]\n",
      "loss: 0.377043 [12864/60000]\n",
      "loss: 0.627886 [19264/60000]\n",
      "loss: 0.549543 [25664/60000]\n",
      "loss: 0.549465 [32064/60000]\n",
      "loss: 0.548884 [38464/60000]\n",
      "loss: 0.665962 [44864/60000]\n",
      "loss: 0.644206 [51264/60000]\n",
      "loss: 0.516517 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.541598 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.450339 [   64/60000]\n",
      "loss: 0.554166 [ 6464/60000]\n",
      "loss: 0.371984 [12864/60000]\n",
      "loss: 0.622448 [19264/60000]\n",
      "loss: 0.544082 [25664/60000]\n",
      "loss: 0.545432 [32064/60000]\n",
      "loss: 0.543420 [38464/60000]\n",
      "loss: 0.666828 [44864/60000]\n",
      "loss: 0.642992 [51264/60000]\n",
      "loss: 0.509221 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.537140 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.443627 [   64/60000]\n",
      "loss: 0.548411 [ 6464/60000]\n",
      "loss: 0.367181 [12864/60000]\n",
      "loss: 0.617168 [19264/60000]\n",
      "loss: 0.538689 [25664/60000]\n",
      "loss: 0.541425 [32064/60000]\n",
      "loss: 0.538331 [38464/60000]\n",
      "loss: 0.667750 [44864/60000]\n",
      "loss: 0.641850 [51264/60000]\n",
      "loss: 0.502241 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.532970 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.437210 [   64/60000]\n",
      "loss: 0.543053 [ 6464/60000]\n",
      "loss: 0.362618 [12864/60000]\n",
      "loss: 0.612012 [19264/60000]\n",
      "loss: 0.533394 [25664/60000]\n",
      "loss: 0.537487 [32064/60000]\n",
      "loss: 0.533603 [38464/60000]\n",
      "loss: 0.668694 [44864/60000]\n",
      "loss: 0.640713 [51264/60000]\n",
      "loss: 0.495549 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.529061 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.431058 [   64/60000]\n",
      "loss: 0.538072 [ 6464/60000]\n",
      "loss: 0.358307 [12864/60000]\n",
      "loss: 0.607001 [19264/60000]\n",
      "loss: 0.528187 [25664/60000]\n",
      "loss: 0.533530 [32064/60000]\n",
      "loss: 0.529196 [38464/60000]\n",
      "loss: 0.669558 [44864/60000]\n",
      "loss: 0.639518 [51264/60000]\n",
      "loss: 0.489159 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.525387 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.425164 [   64/60000]\n",
      "loss: 0.533444 [ 6464/60000]\n",
      "loss: 0.354216 [12864/60000]\n",
      "loss: 0.602167 [19264/60000]\n",
      "loss: 0.523079 [25664/60000]\n",
      "loss: 0.529673 [32064/60000]\n",
      "loss: 0.525093 [38464/60000]\n",
      "loss: 0.670331 [44864/60000]\n",
      "loss: 0.638286 [51264/60000]\n",
      "loss: 0.483058 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.521922 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.419509 [   64/60000]\n",
      "loss: 0.529097 [ 6464/60000]\n",
      "loss: 0.350279 [12864/60000]\n",
      "loss: 0.597510 [19264/60000]\n",
      "loss: 0.517976 [25664/60000]\n",
      "loss: 0.525896 [32064/60000]\n",
      "loss: 0.521300 [38464/60000]\n",
      "loss: 0.671015 [44864/60000]\n",
      "loss: 0.636956 [51264/60000]\n",
      "loss: 0.477294 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.518654 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.414099 [   64/60000]\n",
      "loss: 0.525029 [ 6464/60000]\n",
      "loss: 0.346551 [12864/60000]\n",
      "loss: 0.592948 [19264/60000]\n",
      "loss: 0.512991 [25664/60000]\n",
      "loss: 0.522129 [32064/60000]\n",
      "loss: 0.517686 [38464/60000]\n",
      "loss: 0.671596 [44864/60000]\n",
      "loss: 0.635545 [51264/60000]\n",
      "loss: 0.471812 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.515567 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.408898 [   64/60000]\n",
      "loss: 0.521225 [ 6464/60000]\n",
      "loss: 0.343028 [12864/60000]\n",
      "loss: 0.588474 [19264/60000]\n",
      "loss: 0.508045 [25664/60000]\n",
      "loss: 0.518496 [32064/60000]\n",
      "loss: 0.514294 [38464/60000]\n",
      "loss: 0.672057 [44864/60000]\n",
      "loss: 0.634052 [51264/60000]\n",
      "loss: 0.466594 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.512642 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.403904 [   64/60000]\n",
      "loss: 0.517743 [ 6464/60000]\n",
      "loss: 0.339674 [12864/60000]\n",
      "loss: 0.584097 [19264/60000]\n",
      "loss: 0.503230 [25664/60000]\n",
      "loss: 0.514971 [32064/60000]\n",
      "loss: 0.511034 [38464/60000]\n",
      "loss: 0.672269 [44864/60000]\n",
      "loss: 0.632470 [51264/60000]\n",
      "loss: 0.461664 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.509874 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.399047 [   64/60000]\n",
      "loss: 0.514420 [ 6464/60000]\n",
      "loss: 0.336439 [12864/60000]\n",
      "loss: 0.579826 [19264/60000]\n",
      "loss: 0.498515 [25664/60000]\n",
      "loss: 0.511557 [32064/60000]\n",
      "loss: 0.507899 [38464/60000]\n",
      "loss: 0.672310 [44864/60000]\n",
      "loss: 0.630812 [51264/60000]\n",
      "loss: 0.457005 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.507248 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.394364 [   64/60000]\n",
      "loss: 0.511347 [ 6464/60000]\n",
      "loss: 0.333343 [12864/60000]\n",
      "loss: 0.575737 [19264/60000]\n",
      "loss: 0.493880 [25664/60000]\n",
      "loss: 0.508249 [32064/60000]\n",
      "loss: 0.504762 [38464/60000]\n",
      "loss: 0.672191 [44864/60000]\n",
      "loss: 0.628914 [51264/60000]\n",
      "loss: 0.452724 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.504744 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.389846 [   64/60000]\n",
      "loss: 0.508467 [ 6464/60000]\n",
      "loss: 0.330330 [12864/60000]\n",
      "loss: 0.571678 [19264/60000]\n",
      "loss: 0.489355 [25664/60000]\n",
      "loss: 0.505002 [32064/60000]\n",
      "loss: 0.501791 [38464/60000]\n",
      "loss: 0.671886 [44864/60000]\n",
      "loss: 0.626983 [51264/60000]\n",
      "loss: 0.448580 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.502363 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.385497 [   64/60000]\n",
      "loss: 0.505749 [ 6464/60000]\n",
      "loss: 0.327331 [12864/60000]\n",
      "loss: 0.567684 [19264/60000]\n",
      "loss: 0.484937 [25664/60000]\n",
      "loss: 0.501832 [32064/60000]\n",
      "loss: 0.498883 [38464/60000]\n",
      "loss: 0.671304 [44864/60000]\n",
      "loss: 0.625183 [51264/60000]\n",
      "loss: 0.444680 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.500093 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.381205 [   64/60000]\n",
      "loss: 0.503191 [ 6464/60000]\n",
      "loss: 0.324527 [12864/60000]\n",
      "loss: 0.563859 [19264/60000]\n",
      "loss: 0.480774 [25664/60000]\n",
      "loss: 0.498814 [32064/60000]\n",
      "loss: 0.496154 [38464/60000]\n",
      "loss: 0.670584 [44864/60000]\n",
      "loss: 0.623382 [51264/60000]\n",
      "loss: 0.441057 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497920 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.376972 [   64/60000]\n",
      "loss: 0.500767 [ 6464/60000]\n",
      "loss: 0.321909 [12864/60000]\n",
      "loss: 0.560305 [19264/60000]\n",
      "loss: 0.476769 [25664/60000]\n",
      "loss: 0.495853 [32064/60000]\n",
      "loss: 0.493502 [38464/60000]\n",
      "loss: 0.669715 [44864/60000]\n",
      "loss: 0.621549 [51264/60000]\n",
      "loss: 0.437672 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.495840 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.372858 [   64/60000]\n",
      "loss: 0.498418 [ 6464/60000]\n",
      "loss: 0.319322 [12864/60000]\n",
      "loss: 0.556904 [19264/60000]\n",
      "loss: 0.472872 [25664/60000]\n",
      "loss: 0.493072 [32064/60000]\n",
      "loss: 0.490981 [38464/60000]\n",
      "loss: 0.668723 [44864/60000]\n",
      "loss: 0.619748 [51264/60000]\n",
      "loss: 0.434463 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.493846 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.368872 [   64/60000]\n",
      "loss: 0.496142 [ 6464/60000]\n",
      "loss: 0.316864 [12864/60000]\n",
      "loss: 0.553610 [19264/60000]\n",
      "loss: 0.469089 [25664/60000]\n",
      "loss: 0.490340 [32064/60000]\n",
      "loss: 0.488535 [38464/60000]\n",
      "loss: 0.667654 [44864/60000]\n",
      "loss: 0.617924 [51264/60000]\n",
      "loss: 0.431548 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.491931 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.365023 [   64/60000]\n",
      "loss: 0.493983 [ 6464/60000]\n",
      "loss: 0.314513 [12864/60000]\n",
      "loss: 0.550432 [19264/60000]\n",
      "loss: 0.465409 [25664/60000]\n",
      "loss: 0.487680 [32064/60000]\n",
      "loss: 0.486223 [38464/60000]\n",
      "loss: 0.666468 [44864/60000]\n",
      "loss: 0.616088 [51264/60000]\n",
      "loss: 0.428804 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.490090 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.361273 [   64/60000]\n",
      "loss: 0.491895 [ 6464/60000]\n",
      "loss: 0.312239 [12864/60000]\n",
      "loss: 0.547374 [19264/60000]\n",
      "loss: 0.461899 [25664/60000]\n",
      "loss: 0.485017 [32064/60000]\n",
      "loss: 0.483936 [38464/60000]\n",
      "loss: 0.665113 [44864/60000]\n",
      "loss: 0.614250 [51264/60000]\n",
      "loss: 0.426265 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.488316 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.357675 [   64/60000]\n",
      "loss: 0.489867 [ 6464/60000]\n",
      "loss: 0.310023 [12864/60000]\n",
      "loss: 0.544450 [19264/60000]\n",
      "loss: 0.458454 [25664/60000]\n",
      "loss: 0.482592 [32064/60000]\n",
      "loss: 0.481697 [38464/60000]\n",
      "loss: 0.663717 [44864/60000]\n",
      "loss: 0.612410 [51264/60000]\n",
      "loss: 0.423846 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.486603 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.354166 [   64/60000]\n",
      "loss: 0.487932 [ 6464/60000]\n",
      "loss: 0.307872 [12864/60000]\n",
      "loss: 0.541579 [19264/60000]\n",
      "loss: 0.455166 [25664/60000]\n",
      "loss: 0.480228 [32064/60000]\n",
      "loss: 0.479522 [38464/60000]\n",
      "loss: 0.662234 [44864/60000]\n",
      "loss: 0.610530 [51264/60000]\n",
      "loss: 0.421568 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.484946 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.350730 [   64/60000]\n",
      "loss: 0.486079 [ 6464/60000]\n",
      "loss: 0.305801 [12864/60000]\n",
      "loss: 0.538805 [19264/60000]\n",
      "loss: 0.451931 [25664/60000]\n",
      "loss: 0.477959 [32064/60000]\n",
      "loss: 0.477449 [38464/60000]\n",
      "loss: 0.660768 [44864/60000]\n",
      "loss: 0.608660 [51264/60000]\n",
      "loss: 0.419394 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.483346 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.347371 [   64/60000]\n",
      "loss: 0.484313 [ 6464/60000]\n",
      "loss: 0.303807 [12864/60000]\n",
      "loss: 0.536127 [19264/60000]\n",
      "loss: 0.448769 [25664/60000]\n",
      "loss: 0.475766 [32064/60000]\n",
      "loss: 0.475459 [38464/60000]\n",
      "loss: 0.659179 [44864/60000]\n",
      "loss: 0.606872 [51264/60000]\n",
      "loss: 0.417360 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.481800 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.344139 [   64/60000]\n",
      "loss: 0.482580 [ 6464/60000]\n",
      "loss: 0.301884 [12864/60000]\n",
      "loss: 0.533561 [19264/60000]\n",
      "loss: 0.445708 [25664/60000]\n",
      "loss: 0.473699 [32064/60000]\n",
      "loss: 0.473495 [38464/60000]\n",
      "loss: 0.657614 [44864/60000]\n",
      "loss: 0.605071 [51264/60000]\n",
      "loss: 0.415400 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.480300 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.341035 [   64/60000]\n",
      "loss: 0.480933 [ 6464/60000]\n",
      "loss: 0.300068 [12864/60000]\n",
      "loss: 0.531086 [19264/60000]\n",
      "loss: 0.442773 [25664/60000]\n",
      "loss: 0.471731 [32064/60000]\n",
      "loss: 0.471544 [38464/60000]\n",
      "loss: 0.655915 [44864/60000]\n",
      "loss: 0.603362 [51264/60000]\n",
      "loss: 0.413619 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.478843 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.338033 [   64/60000]\n",
      "loss: 0.479290 [ 6464/60000]\n",
      "loss: 0.298286 [12864/60000]\n",
      "loss: 0.528720 [19264/60000]\n",
      "loss: 0.439894 [25664/60000]\n",
      "loss: 0.469789 [32064/60000]\n",
      "loss: 0.469672 [38464/60000]\n",
      "loss: 0.654196 [44864/60000]\n",
      "loss: 0.601718 [51264/60000]\n",
      "loss: 0.412021 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.477425 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.335070 [   64/60000]\n",
      "loss: 0.477686 [ 6464/60000]\n",
      "loss: 0.296595 [12864/60000]\n",
      "loss: 0.526379 [19264/60000]\n",
      "loss: 0.437093 [25664/60000]\n",
      "loss: 0.467897 [32064/60000]\n",
      "loss: 0.467815 [38464/60000]\n",
      "loss: 0.652416 [44864/60000]\n",
      "loss: 0.600008 [51264/60000]\n",
      "loss: 0.410492 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.476042 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.332183 [   64/60000]\n",
      "loss: 0.476082 [ 6464/60000]\n",
      "loss: 0.294932 [12864/60000]\n",
      "loss: 0.524093 [19264/60000]\n",
      "loss: 0.434363 [25664/60000]\n",
      "loss: 0.465991 [32064/60000]\n",
      "loss: 0.465989 [38464/60000]\n",
      "loss: 0.650604 [44864/60000]\n",
      "loss: 0.598268 [51264/60000]\n",
      "loss: 0.409040 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.474698 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.329392 [   64/60000]\n",
      "loss: 0.474524 [ 6464/60000]\n",
      "loss: 0.293285 [12864/60000]\n",
      "loss: 0.521853 [19264/60000]\n",
      "loss: 0.431703 [25664/60000]\n",
      "loss: 0.464177 [32064/60000]\n",
      "loss: 0.464211 [38464/60000]\n",
      "loss: 0.648792 [44864/60000]\n",
      "loss: 0.596577 [51264/60000]\n",
      "loss: 0.407649 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.473388 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.326689 [   64/60000]\n",
      "loss: 0.473009 [ 6464/60000]\n",
      "loss: 0.291701 [12864/60000]\n",
      "loss: 0.519710 [19264/60000]\n",
      "loss: 0.429137 [25664/60000]\n",
      "loss: 0.462415 [32064/60000]\n",
      "loss: 0.462462 [38464/60000]\n",
      "loss: 0.646941 [44864/60000]\n",
      "loss: 0.594886 [51264/60000]\n",
      "loss: 0.406293 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.472104 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.324042 [   64/60000]\n",
      "loss: 0.471532 [ 6464/60000]\n",
      "loss: 0.290190 [12864/60000]\n",
      "loss: 0.517623 [19264/60000]\n",
      "loss: 0.426575 [25664/60000]\n",
      "loss: 0.460754 [32064/60000]\n",
      "loss: 0.460749 [38464/60000]\n",
      "loss: 0.645083 [44864/60000]\n",
      "loss: 0.593207 [51264/60000]\n",
      "loss: 0.405065 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.470853 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.321529 [   64/60000]\n",
      "loss: 0.470035 [ 6464/60000]\n",
      "loss: 0.288703 [12864/60000]\n",
      "loss: 0.515683 [19264/60000]\n",
      "loss: 0.424004 [25664/60000]\n",
      "loss: 0.459161 [32064/60000]\n",
      "loss: 0.459090 [38464/60000]\n",
      "loss: 0.643274 [44864/60000]\n",
      "loss: 0.591534 [51264/60000]\n",
      "loss: 0.403912 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.469633 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.319006 [   64/60000]\n",
      "loss: 0.468581 [ 6464/60000]\n",
      "loss: 0.287229 [12864/60000]\n",
      "loss: 0.513785 [19264/60000]\n",
      "loss: 0.421531 [25664/60000]\n",
      "loss: 0.457599 [32064/60000]\n",
      "loss: 0.457446 [38464/60000]\n",
      "loss: 0.641454 [44864/60000]\n",
      "loss: 0.589803 [51264/60000]\n",
      "loss: 0.402762 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.468439 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.316602 [   64/60000]\n",
      "loss: 0.467149 [ 6464/60000]\n",
      "loss: 0.285786 [12864/60000]\n",
      "loss: 0.511960 [19264/60000]\n",
      "loss: 0.419182 [25664/60000]\n",
      "loss: 0.456062 [32064/60000]\n",
      "loss: 0.455810 [38464/60000]\n",
      "loss: 0.639606 [44864/60000]\n",
      "loss: 0.588096 [51264/60000]\n",
      "loss: 0.401591 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.467263 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.314278 [   64/60000]\n",
      "loss: 0.465746 [ 6464/60000]\n",
      "loss: 0.284406 [12864/60000]\n",
      "loss: 0.510233 [19264/60000]\n",
      "loss: 0.416821 [25664/60000]\n",
      "loss: 0.454519 [32064/60000]\n",
      "loss: 0.454252 [38464/60000]\n",
      "loss: 0.637815 [44864/60000]\n",
      "loss: 0.586471 [51264/60000]\n",
      "loss: 0.400491 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.466113 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.312024 [   64/60000]\n",
      "loss: 0.464367 [ 6464/60000]\n",
      "loss: 0.283075 [12864/60000]\n",
      "loss: 0.508557 [19264/60000]\n",
      "loss: 0.414514 [25664/60000]\n",
      "loss: 0.452995 [32064/60000]\n",
      "loss: 0.452732 [38464/60000]\n",
      "loss: 0.635982 [44864/60000]\n",
      "loss: 0.584858 [51264/60000]\n",
      "loss: 0.399474 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.464982 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.309882 [   64/60000]\n",
      "loss: 0.463023 [ 6464/60000]\n",
      "loss: 0.281779 [12864/60000]\n",
      "loss: 0.506912 [19264/60000]\n",
      "loss: 0.412223 [25664/60000]\n",
      "loss: 0.451566 [32064/60000]\n",
      "loss: 0.451206 [38464/60000]\n",
      "loss: 0.634200 [44864/60000]\n",
      "loss: 0.583338 [51264/60000]\n",
      "loss: 0.398484 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.463878 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.307754 [   64/60000]\n",
      "loss: 0.461691 [ 6464/60000]\n",
      "loss: 0.280488 [12864/60000]\n",
      "loss: 0.505270 [19264/60000]\n",
      "loss: 0.410019 [25664/60000]\n",
      "loss: 0.450165 [32064/60000]\n",
      "loss: 0.449693 [38464/60000]\n",
      "loss: 0.632483 [44864/60000]\n",
      "loss: 0.581843 [51264/60000]\n",
      "loss: 0.397508 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.462794 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.305660 [   64/60000]\n",
      "loss: 0.460335 [ 6464/60000]\n",
      "loss: 0.279210 [12864/60000]\n",
      "loss: 0.503673 [19264/60000]\n",
      "loss: 0.407852 [25664/60000]\n",
      "loss: 0.448776 [32064/60000]\n",
      "loss: 0.448221 [38464/60000]\n",
      "loss: 0.630798 [44864/60000]\n",
      "loss: 0.580320 [51264/60000]\n",
      "loss: 0.396566 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.461731 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.303621 [   64/60000]\n",
      "loss: 0.459011 [ 6464/60000]\n",
      "loss: 0.277948 [12864/60000]\n",
      "loss: 0.502129 [19264/60000]\n",
      "loss: 0.405764 [25664/60000]\n",
      "loss: 0.447397 [32064/60000]\n",
      "loss: 0.446758 [38464/60000]\n",
      "loss: 0.629138 [44864/60000]\n",
      "loss: 0.578789 [51264/60000]\n",
      "loss: 0.395660 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.460685 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.301684 [   64/60000]\n",
      "loss: 0.457703 [ 6464/60000]\n",
      "loss: 0.276748 [12864/60000]\n",
      "loss: 0.500572 [19264/60000]\n",
      "loss: 0.403739 [25664/60000]\n",
      "loss: 0.446068 [32064/60000]\n",
      "loss: 0.445304 [38464/60000]\n",
      "loss: 0.627460 [44864/60000]\n",
      "loss: 0.577312 [51264/60000]\n",
      "loss: 0.394720 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.459657 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.299792 [   64/60000]\n",
      "loss: 0.456420 [ 6464/60000]\n",
      "loss: 0.275587 [12864/60000]\n",
      "loss: 0.499031 [19264/60000]\n",
      "loss: 0.401648 [25664/60000]\n",
      "loss: 0.444766 [32064/60000]\n",
      "loss: 0.443874 [38464/60000]\n",
      "loss: 0.625818 [44864/60000]\n",
      "loss: 0.575821 [51264/60000]\n",
      "loss: 0.393867 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.458646 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.297945 [   64/60000]\n",
      "loss: 0.455169 [ 6464/60000]\n",
      "loss: 0.274470 [12864/60000]\n",
      "loss: 0.497520 [19264/60000]\n",
      "loss: 0.399609 [25664/60000]\n",
      "loss: 0.443529 [32064/60000]\n",
      "loss: 0.442466 [38464/60000]\n",
      "loss: 0.624193 [44864/60000]\n",
      "loss: 0.574375 [51264/60000]\n",
      "loss: 0.393054 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.457657 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.296125 [   64/60000]\n",
      "loss: 0.453905 [ 6464/60000]\n",
      "loss: 0.273373 [12864/60000]\n",
      "loss: 0.496010 [19264/60000]\n",
      "loss: 0.397633 [25664/60000]\n",
      "loss: 0.442324 [32064/60000]\n",
      "loss: 0.441095 [38464/60000]\n",
      "loss: 0.622597 [44864/60000]\n",
      "loss: 0.572945 [51264/60000]\n",
      "loss: 0.392247 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.456676 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.294338 [   64/60000]\n",
      "loss: 0.452598 [ 6464/60000]\n",
      "loss: 0.272276 [12864/60000]\n",
      "loss: 0.494491 [19264/60000]\n",
      "loss: 0.395712 [25664/60000]\n",
      "loss: 0.441118 [32064/60000]\n",
      "loss: 0.439715 [38464/60000]\n",
      "loss: 0.620947 [44864/60000]\n",
      "loss: 0.571517 [51264/60000]\n",
      "loss: 0.391456 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.455710 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.292610 [   64/60000]\n",
      "loss: 0.451337 [ 6464/60000]\n",
      "loss: 0.271219 [12864/60000]\n",
      "loss: 0.493017 [19264/60000]\n",
      "loss: 0.393867 [25664/60000]\n",
      "loss: 0.439965 [32064/60000]\n",
      "loss: 0.438356 [38464/60000]\n",
      "loss: 0.619300 [44864/60000]\n",
      "loss: 0.570081 [51264/60000]\n",
      "loss: 0.390679 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.454750 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.290952 [   64/60000]\n",
      "loss: 0.450114 [ 6464/60000]\n",
      "loss: 0.270243 [12864/60000]\n",
      "loss: 0.491557 [19264/60000]\n",
      "loss: 0.392130 [25664/60000]\n",
      "loss: 0.438869 [32064/60000]\n",
      "loss: 0.437064 [38464/60000]\n",
      "loss: 0.617667 [44864/60000]\n",
      "loss: 0.568645 [51264/60000]\n",
      "loss: 0.389951 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.453798 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.289403 [   64/60000]\n",
      "loss: 0.448882 [ 6464/60000]\n",
      "loss: 0.269344 [12864/60000]\n",
      "loss: 0.490097 [19264/60000]\n",
      "loss: 0.390336 [25664/60000]\n",
      "loss: 0.437777 [32064/60000]\n",
      "loss: 0.435747 [38464/60000]\n",
      "loss: 0.616033 [44864/60000]\n",
      "loss: 0.567321 [51264/60000]\n",
      "loss: 0.389331 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.452858 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.287919 [   64/60000]\n",
      "loss: 0.447697 [ 6464/60000]\n",
      "loss: 0.268469 [12864/60000]\n",
      "loss: 0.488646 [19264/60000]\n",
      "loss: 0.388587 [25664/60000]\n",
      "loss: 0.436676 [32064/60000]\n",
      "loss: 0.434451 [38464/60000]\n",
      "loss: 0.614373 [44864/60000]\n",
      "loss: 0.565888 [51264/60000]\n",
      "loss: 0.388710 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.451921 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.286425 [   64/60000]\n",
      "loss: 0.446522 [ 6464/60000]\n",
      "loss: 0.267639 [12864/60000]\n",
      "loss: 0.487185 [19264/60000]\n",
      "loss: 0.386828 [25664/60000]\n",
      "loss: 0.435551 [32064/60000]\n",
      "loss: 0.433119 [38464/60000]\n",
      "loss: 0.612698 [44864/60000]\n",
      "loss: 0.564179 [51264/60000]\n",
      "loss: 0.387977 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.450989 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.284909 [   64/60000]\n",
      "loss: 0.445372 [ 6464/60000]\n",
      "loss: 0.266781 [12864/60000]\n",
      "loss: 0.485693 [19264/60000]\n",
      "loss: 0.385049 [25664/60000]\n",
      "loss: 0.434478 [32064/60000]\n",
      "loss: 0.431771 [38464/60000]\n",
      "loss: 0.611002 [44864/60000]\n",
      "loss: 0.562455 [51264/60000]\n",
      "loss: 0.387326 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.450051 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.283441 [   64/60000]\n",
      "loss: 0.444198 [ 6464/60000]\n",
      "loss: 0.265958 [12864/60000]\n",
      "loss: 0.484258 [19264/60000]\n",
      "loss: 0.383030 [25664/60000]\n",
      "loss: 0.433280 [32064/60000]\n",
      "loss: 0.430384 [38464/60000]\n",
      "loss: 0.609352 [44864/60000]\n",
      "loss: 0.560872 [51264/60000]\n",
      "loss: 0.386678 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.449103 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.281953 [   64/60000]\n",
      "loss: 0.443074 [ 6464/60000]\n",
      "loss: 0.265243 [12864/60000]\n",
      "loss: 0.482818 [19264/60000]\n",
      "loss: 0.381273 [25664/60000]\n",
      "loss: 0.431869 [32064/60000]\n",
      "loss: 0.429168 [38464/60000]\n",
      "loss: 0.607715 [44864/60000]\n",
      "loss: 0.559406 [51264/60000]\n",
      "loss: 0.385746 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.448169 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.280266 [   64/60000]\n",
      "loss: 0.442053 [ 6464/60000]\n",
      "loss: 0.264561 [12864/60000]\n",
      "loss: 0.481354 [19264/60000]\n",
      "loss: 0.379788 [25664/60000]\n",
      "loss: 0.430442 [32064/60000]\n",
      "loss: 0.428042 [38464/60000]\n",
      "loss: 0.606205 [44864/60000]\n",
      "loss: 0.557888 [51264/60000]\n",
      "loss: 0.385059 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.447281 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.278843 [   64/60000]\n",
      "loss: 0.441002 [ 6464/60000]\n",
      "loss: 0.263878 [12864/60000]\n",
      "loss: 0.479860 [19264/60000]\n",
      "loss: 0.378232 [25664/60000]\n",
      "loss: 0.429182 [32064/60000]\n",
      "loss: 0.426941 [38464/60000]\n",
      "loss: 0.604777 [44864/60000]\n",
      "loss: 0.556472 [51264/60000]\n",
      "loss: 0.384507 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.446416 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.277444 [   64/60000]\n",
      "loss: 0.439897 [ 6464/60000]\n",
      "loss: 0.263174 [12864/60000]\n",
      "loss: 0.478390 [19264/60000]\n",
      "loss: 0.376601 [25664/60000]\n",
      "loss: 0.427993 [32064/60000]\n",
      "loss: 0.425843 [38464/60000]\n",
      "loss: 0.603351 [44864/60000]\n",
      "loss: 0.554977 [51264/60000]\n",
      "loss: 0.383993 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.445571 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.276101 [   64/60000]\n",
      "loss: 0.438631 [ 6464/60000]\n",
      "loss: 0.262481 [12864/60000]\n",
      "loss: 0.476959 [19264/60000]\n",
      "loss: 0.374997 [25664/60000]\n",
      "loss: 0.426873 [32064/60000]\n",
      "loss: 0.424724 [38464/60000]\n",
      "loss: 0.601981 [44864/60000]\n",
      "loss: 0.553636 [51264/60000]\n",
      "loss: 0.383477 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.444734 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.274822 [   64/60000]\n",
      "loss: 0.437343 [ 6464/60000]\n",
      "loss: 0.261813 [12864/60000]\n",
      "loss: 0.475513 [19264/60000]\n",
      "loss: 0.373430 [25664/60000]\n",
      "loss: 0.425775 [32064/60000]\n",
      "loss: 0.423572 [38464/60000]\n",
      "loss: 0.600532 [44864/60000]\n",
      "loss: 0.552279 [51264/60000]\n",
      "loss: 0.382946 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.443911 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.273565 [   64/60000]\n",
      "loss: 0.436119 [ 6464/60000]\n",
      "loss: 0.261133 [12864/60000]\n",
      "loss: 0.474106 [19264/60000]\n",
      "loss: 0.371896 [25664/60000]\n",
      "loss: 0.424685 [32064/60000]\n",
      "loss: 0.422449 [38464/60000]\n",
      "loss: 0.599150 [44864/60000]\n",
      "loss: 0.550994 [51264/60000]\n",
      "loss: 0.382423 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.443095 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.272318 [   64/60000]\n",
      "loss: 0.434936 [ 6464/60000]\n",
      "loss: 0.260462 [12864/60000]\n",
      "loss: 0.472689 [19264/60000]\n",
      "loss: 0.370361 [25664/60000]\n",
      "loss: 0.423603 [32064/60000]\n",
      "loss: 0.421348 [38464/60000]\n",
      "loss: 0.597753 [44864/60000]\n",
      "loss: 0.549815 [51264/60000]\n",
      "loss: 0.381828 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.442285 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.271093 [   64/60000]\n",
      "loss: 0.433725 [ 6464/60000]\n",
      "loss: 0.259798 [12864/60000]\n",
      "loss: 0.471266 [19264/60000]\n",
      "loss: 0.368867 [25664/60000]\n",
      "loss: 0.422530 [32064/60000]\n",
      "loss: 0.420259 [38464/60000]\n",
      "loss: 0.596276 [44864/60000]\n",
      "loss: 0.548615 [51264/60000]\n",
      "loss: 0.381260 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.441478 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.269924 [   64/60000]\n",
      "loss: 0.432657 [ 6464/60000]\n",
      "loss: 0.259132 [12864/60000]\n",
      "loss: 0.469818 [19264/60000]\n",
      "loss: 0.367360 [25664/60000]\n",
      "loss: 0.421521 [32064/60000]\n",
      "loss: 0.419159 [38464/60000]\n",
      "loss: 0.594727 [44864/60000]\n",
      "loss: 0.547471 [51264/60000]\n",
      "loss: 0.380766 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.440675 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.268805 [   64/60000]\n",
      "loss: 0.431589 [ 6464/60000]\n",
      "loss: 0.258472 [12864/60000]\n",
      "loss: 0.468375 [19264/60000]\n",
      "loss: 0.365900 [25664/60000]\n",
      "loss: 0.420489 [32064/60000]\n",
      "loss: 0.418073 [38464/60000]\n",
      "loss: 0.593199 [44864/60000]\n",
      "loss: 0.546291 [51264/60000]\n",
      "loss: 0.380280 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.439880 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.267710 [   64/60000]\n",
      "loss: 0.430510 [ 6464/60000]\n",
      "loss: 0.257855 [12864/60000]\n",
      "loss: 0.466951 [19264/60000]\n",
      "loss: 0.364465 [25664/60000]\n",
      "loss: 0.419449 [32064/60000]\n",
      "loss: 0.416972 [38464/60000]\n",
      "loss: 0.591667 [44864/60000]\n",
      "loss: 0.545178 [51264/60000]\n",
      "loss: 0.379698 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.439089 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.266628 [   64/60000]\n",
      "loss: 0.429378 [ 6464/60000]\n",
      "loss: 0.257333 [12864/60000]\n",
      "loss: 0.465593 [19264/60000]\n",
      "loss: 0.363074 [25664/60000]\n",
      "loss: 0.418355 [32064/60000]\n",
      "loss: 0.415858 [38464/60000]\n",
      "loss: 0.590139 [44864/60000]\n",
      "loss: 0.544111 [51264/60000]\n",
      "loss: 0.379082 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.438300 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.265500 [   64/60000]\n",
      "loss: 0.428194 [ 6464/60000]\n",
      "loss: 0.256783 [12864/60000]\n",
      "loss: 0.464285 [19264/60000]\n",
      "loss: 0.361744 [25664/60000]\n",
      "loss: 0.417168 [32064/60000]\n",
      "loss: 0.414763 [38464/60000]\n",
      "loss: 0.588643 [44864/60000]\n",
      "loss: 0.543067 [51264/60000]\n",
      "loss: 0.378485 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.437513 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.264353 [   64/60000]\n",
      "loss: 0.427027 [ 6464/60000]\n",
      "loss: 0.256184 [12864/60000]\n",
      "loss: 0.463005 [19264/60000]\n",
      "loss: 0.360465 [25664/60000]\n",
      "loss: 0.416006 [32064/60000]\n",
      "loss: 0.413645 [38464/60000]\n",
      "loss: 0.587086 [44864/60000]\n",
      "loss: 0.541985 [51264/60000]\n",
      "loss: 0.377953 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.436737 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.263278 [   64/60000]\n",
      "loss: 0.425807 [ 6464/60000]\n",
      "loss: 0.255664 [12864/60000]\n",
      "loss: 0.461683 [19264/60000]\n",
      "loss: 0.359134 [25664/60000]\n",
      "loss: 0.414919 [32064/60000]\n",
      "loss: 0.412544 [38464/60000]\n",
      "loss: 0.585461 [44864/60000]\n",
      "loss: 0.540850 [51264/60000]\n",
      "loss: 0.377429 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.435966 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.262250 [   64/60000]\n",
      "loss: 0.424603 [ 6464/60000]\n",
      "loss: 0.255130 [12864/60000]\n",
      "loss: 0.460482 [19264/60000]\n",
      "loss: 0.357797 [25664/60000]\n",
      "loss: 0.413841 [32064/60000]\n",
      "loss: 0.411368 [38464/60000]\n",
      "loss: 0.583965 [44864/60000]\n",
      "loss: 0.539597 [51264/60000]\n",
      "loss: 0.376872 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.435205 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.261270 [   64/60000]\n",
      "loss: 0.423422 [ 6464/60000]\n",
      "loss: 0.254493 [12864/60000]\n",
      "loss: 0.459213 [19264/60000]\n",
      "loss: 0.356479 [25664/60000]\n",
      "loss: 0.412765 [32064/60000]\n",
      "loss: 0.410263 [38464/60000]\n",
      "loss: 0.582664 [44864/60000]\n",
      "loss: 0.538234 [51264/60000]\n",
      "loss: 0.376378 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.434467 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.260323 [   64/60000]\n",
      "loss: 0.422248 [ 6464/60000]\n",
      "loss: 0.253861 [12864/60000]\n",
      "loss: 0.457943 [19264/60000]\n",
      "loss: 0.355135 [25664/60000]\n",
      "loss: 0.411674 [32064/60000]\n",
      "loss: 0.409129 [38464/60000]\n",
      "loss: 0.581301 [44864/60000]\n",
      "loss: 0.536906 [51264/60000]\n",
      "loss: 0.375827 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.433734 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.259388 [   64/60000]\n",
      "loss: 0.421059 [ 6464/60000]\n",
      "loss: 0.253289 [12864/60000]\n",
      "loss: 0.456705 [19264/60000]\n",
      "loss: 0.353783 [25664/60000]\n",
      "loss: 0.410641 [32064/60000]\n",
      "loss: 0.407984 [38464/60000]\n",
      "loss: 0.579875 [44864/60000]\n",
      "loss: 0.535602 [51264/60000]\n",
      "loss: 0.375285 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.433014 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.258446 [   64/60000]\n",
      "loss: 0.419924 [ 6464/60000]\n",
      "loss: 0.252656 [12864/60000]\n",
      "loss: 0.455482 [19264/60000]\n",
      "loss: 0.352491 [25664/60000]\n",
      "loss: 0.409694 [32064/60000]\n",
      "loss: 0.406845 [38464/60000]\n",
      "loss: 0.578562 [44864/60000]\n",
      "loss: 0.534365 [51264/60000]\n",
      "loss: 0.374798 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.432305 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.257543 [   64/60000]\n",
      "loss: 0.418848 [ 6464/60000]\n",
      "loss: 0.252071 [12864/60000]\n",
      "loss: 0.454205 [19264/60000]\n",
      "loss: 0.351213 [25664/60000]\n",
      "loss: 0.408797 [32064/60000]\n",
      "loss: 0.405712 [38464/60000]\n",
      "loss: 0.577184 [44864/60000]\n",
      "loss: 0.533135 [51264/60000]\n",
      "loss: 0.374265 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.431601 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_func, optimizer)\n",
    "    test(test_dataloader, model, loss_func)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d7ccfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Saving Model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691f8880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Model\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "346d835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
